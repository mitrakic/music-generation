{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import random\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files():\n",
    "    \n",
    "    # load in files and normalize to 4 measures\n",
    "    bass = (AudioSegment.from_wav(\"./1/bass.wav\") * 2) - 4\n",
    "    clav = (AudioSegment.from_wav(\"./1/clav.wav\") * 2) - 3\n",
    "    drums = (AudioSegment.from_wav(\"./1/drums.wav\") * 4) - 3\n",
    "    flute = AudioSegment.from_wav(\"./1/flute.wav\") - 2\n",
    "    synth = (AudioSegment.from_wav(\"./1/synth.wav\") * 4)\n",
    "    #print(len(bass), len(clav), len(drums), len(flute), len(synth))\n",
    "\n",
    "    clav2 = (AudioSegment.from_wav(\"./2/clavi.wav\") * 2) - 2\n",
    "    clav3 = AudioSegment.from_wav(\"./2/clavi2.wav\") - 2\n",
    "    drums2 = (AudioSegment.from_wav(\"./2/drums.wav\") * 2) - 3\n",
    "    flute2 = AudioSegment.from_wav(\"./2/flute.wav\") - 2\n",
    "    synth2 = AudioSegment.from_wav(\"./2/synth.wav\") - 1\n",
    "    synth3 = AudioSegment.from_wav(\"./2/synth_alt.wav\") - 1\n",
    "    #print(len(clav2), len(clav3), len(drums2), len(flute2), len(synth2), len(synth3))\n",
    "\n",
    "    #create combinations\n",
    "    c1 = [bass, clav, drums, flute, synth]\n",
    "    c2 = [bass, clav2, drums2, flute2, synth2]\n",
    "    c3 = [bass, clav2, drums2, flute, synth3]\n",
    "    c4 = [bass, clav3, drums2, flute2, synth2]\n",
    "    c5 = [bass, clav2, drums, flute, synth3]\n",
    "    c6 = [bass, clav, drums, flute, synth]\n",
    "    c7 = [bass, clav2, drums, flute2, synth2]\n",
    "    c8 = [bass, clav3, drums2, flute, synth3]\n",
    "\n",
    "    combinations = [c1, c2, c3, c4, c5, c6, c7, c8]\n",
    "    \n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_speeches(seed1, seed2, seed3):\n",
    "    folders = [\"arbenz\", \"armas\", \"paris\", \"larrykramer\", \"vox\"]\n",
    "    files = list()\n",
    "    index = (int(seed1) + int(seed2) + int(seed3)) % 5\n",
    "    print(index)\n",
    "    for i in range(1, 6):\n",
    "        folder = folders[index]\n",
    "        if folder == \"paris\":\n",
    "            files.append(AudioSegment.from_wav(\"./speeches/\" + folders[index] + \"/\" + str(i) + \".wav\")+8)\n",
    "        elif folder == \"vox\":\n",
    "            files.append(AudioSegment.from_wav(\"./speeches/\" + folders[index] + \"/\" + str(i) + \".wav\")+5)\n",
    "        else:\n",
    "            files.append(AudioSegment.from_wav(\"./speeches/\" + folders[index] + \"/\" + str(i) + \".wav\")+2)\n",
    "        #play(files[i-1].reverse())\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_song(combinations, speeches, seed1, seed2, seed3):\n",
    "    random.seed(seed1)\n",
    "    \n",
    "    #introduction\n",
    "    introduction = AudioSegment.silent(duration=0)\n",
    "    intro_length = random.randint(2, 3)\n",
    "    print(intro_length)\n",
    "    last = set()\n",
    "    current = set()\n",
    "    for i in range(intro_length):\n",
    "        combination = combinations[random.randint(0, 7)]\n",
    "        current = last.copy()\n",
    "        curr = AudioSegment.silent(duration=9600)\n",
    "        for e in combination:\n",
    "            if e not in current:\n",
    "                if random.random() > (1.2 / (i+2)):\n",
    "                    current.add(e)\n",
    "        for e in last:\n",
    "            if random.random() < seed1 / 500:\n",
    "                current.remove(e)\n",
    "        if len(current) == 0:\n",
    "            current.add(combinations[0][3])\n",
    "        last = current.copy()\n",
    "        for e in current:\n",
    "            curr = curr.overlay(e, loop=True)\n",
    "        if random.random() < seed2 / 200:\n",
    "            curr -= 3\n",
    "            curr = curr.overlay(speeches[random.randint(0, 4)], loop=False)\n",
    "            print(\"speech\")\n",
    "            #play(curr)\n",
    "        print(i, current)\n",
    "        introduction += curr\n",
    "    introduction = introduction.fade_in(len(introduction))\n",
    "    #play(introduction)\n",
    "    \n",
    "    #middle\n",
    "    random.seed(seed2)\n",
    "    middle = AudioSegment.silent(duration=0)\n",
    "    middle_num_sections = random.randint(5, 8)\n",
    "    print(\"Num sections: \", middle_num_sections)\n",
    "    for i in range(middle_num_sections):\n",
    "        combination = combinations[random.randint(0, 7)]\n",
    "        section_length = random.randint(1, 4)\n",
    "        print(\"Section: \", i, \"Length: \", section_length)\n",
    "        section = AudioSegment.silent(duration=0)\n",
    "        for j in range(section_length):\n",
    "            prev_length = len(current)\n",
    "            current = set()\n",
    "            curr = AudioSegment.silent(duration=9600)\n",
    "            for e in combination:\n",
    "                eee = e\n",
    "                if random.random() < seed2 / 500:\n",
    "                    eee = eee.pan((random.random()*2)-1)\n",
    "                if random.random() < seed3 / 550:\n",
    "                    eee = eee.reverse()\n",
    "                if random.random() > (1.2 / (prev_length+1)):\n",
    "                    current.add(eee)\n",
    "            if len(current) == 0:\n",
    "                current.add(combinations[1][4])\n",
    "            for e in current:\n",
    "                curr = curr.overlay(e, loop=True)\n",
    "            if random.random() < seed3 / 350:\n",
    "                curr -= 3\n",
    "                curr = curr.overlay(speeches[random.randint(0, 4)], loop=False)\n",
    "                print(\"speech\")\n",
    "            elif random.random() < seed3 / 550:\n",
    "                curr -= 3\n",
    "                curr = curr.overlay(speeches[random.randint(0, 4)].reverse(), loop=False)\n",
    "                print(\"speech reversed\")\n",
    "            print(\"Section: \", i, \"Segment: \", j, \"Inst: \", len(current))\n",
    "            section += curr\n",
    "        middle += section\n",
    "    #play(middle)\n",
    "    \n",
    "    #outro\n",
    "    outro = AudioSegment.silent(duration=0)\n",
    "    outro_length = random.randint(1, 3)\n",
    "    print(outro_length)\n",
    "    current = set()\n",
    "    for i in range(outro_length):\n",
    "        current = last.copy()\n",
    "        curr = AudioSegment.silent(duration=9600)\n",
    "        for e in combinations[0]:\n",
    "            if e not in current:\n",
    "                if random.random() > (1.2 / (i+2)):\n",
    "                    current.add(e)\n",
    "        for e in last:\n",
    "            if random.random() < seed1 / 500:\n",
    "                current.remove(e)\n",
    "        if len(current) == 0:\n",
    "            current.add(combinations[1][3])\n",
    "        last = current.copy()\n",
    "        for e in current:\n",
    "            curr = curr.overlay(e, loop=True)\n",
    "        if random.random() < seed1 / 175:\n",
    "            curr -= 3\n",
    "            curr = curr.overlay(speeches[random.randint(0, 4)], loop=False)\n",
    "            print(\"speech\")\n",
    "        print(i, current)\n",
    "        outro += curr\n",
    "    outro = outro.fade_out(len(outro))\n",
    "    \n",
    "    return introduction + middle + outro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199.70859697 206.70610083 202.59857475 255.        ]\n",
      "2\n",
      "2\n",
      "speech\n",
      "0 {<pydub.audio_segment.AudioSegment object at 0x000001C6088DA588>}\n",
      "speech\n",
      "1 {<pydub.audio_segment.AudioSegment object at 0x000001C6088DA358>, <pydub.audio_segment.AudioSegment object at 0x000001C6088DA588>, <pydub.audio_segment.AudioSegment object at 0x000001C6088DA550>, <pydub.audio_segment.AudioSegment object at 0x000001C6088DA518>, <pydub.audio_segment.AudioSegment object at 0x000001C6088DA4E0>}\n",
      "Num sections:  5\n",
      "Section:  0 Length:  2\n",
      "speech\n",
      "Section:  0 Segment:  0 Inst:  4\n",
      "speech\n",
      "Section:  0 Segment:  1 Inst:  5\n",
      "Section:  1 Length:  3\n",
      "speech reversed\n",
      "Section:  1 Segment:  0 Inst:  4\n",
      "speech reversed\n",
      "Section:  1 Segment:  1 Inst:  3\n",
      "speech\n",
      "Section:  1 Segment:  2 Inst:  4\n",
      "Section:  2 Length:  3\n",
      "Section:  2 Segment:  0 Inst:  4\n",
      "speech\n",
      "Section:  2 Segment:  1 Inst:  3\n",
      "speech\n",
      "Section:  2 Segment:  2 Inst:  4\n",
      "Section:  3 Length:  4\n",
      "speech\n",
      "Section:  3 Segment:  0 Inst:  2\n",
      "speech reversed\n",
      "Section:  3 Segment:  1 Inst:  2\n",
      "speech\n",
      "Section:  3 Segment:  2 Inst:  4\n",
      "speech\n",
      "Section:  3 Segment:  3 Inst:  4\n",
      "Section:  4 Length:  4\n",
      "speech reversed\n",
      "Section:  4 Segment:  0 Inst:  3\n",
      "Section:  4 Segment:  1 Inst:  4\n",
      "Section:  4 Segment:  2 Inst:  2\n",
      "speech\n",
      "Section:  4 Segment:  3 Inst:  3\n",
      "3\n",
      "speech\n",
      "0 {<pydub.audio_segment.AudioSegment object at 0x000001C6088DA4E0>}\n",
      "speech\n",
      "1 {<pydub.audio_segment.AudioSegment object at 0x000001C6088DA4E0>, <pydub.audio_segment.AudioSegment object at 0x000001C6088DA358>, <pydub.audio_segment.AudioSegment object at 0x000001C6088DA400>}\n",
      "speech\n",
      "2 {<pydub.audio_segment.AudioSegment object at 0x000001C6088DA400>, <pydub.audio_segment.AudioSegment object at 0x000001C6088DA438>, <pydub.audio_segment.AudioSegment object at 0x000001C6088DA320>, <pydub.audio_segment.AudioSegment object at 0x000001C6088DA4E0>, <pydub.audio_segment.AudioSegment object at 0x000001C605472BE0>}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0e7e92129452>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msong\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_song\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_speeches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-056fc29e4245>\u001b[0m in \u001b[0;36mcreate_song\u001b[1;34m(combinations, speeches, seed1, seed2, seed3)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0moutro\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcurr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[0moutro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfade_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutro\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mintroduction\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmiddle\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moutro\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mitra-Kiciman\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfade_out\u001b[1;34m(self, duration)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfade_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfade\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_gain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfade_in\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mitra-Kiciman\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfade\u001b[1;34m(self, to_gain, from_gain, start, end, duration)\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m                 \u001b[0mvolume_change\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrom_power\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscale_step\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1246\u001b[1;33m                 \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1247\u001b[0m                 chunk = audioop.mul(chunk._data,\n\u001b[0;32m   1248\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mitra-Kiciman\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, millisecond)\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmillisecond\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image = Image.open(\"C:\\\\Users\\\\Mitra Kiciman\\\\Pictures\\\\cache.png\")\n",
    "data = numpy.mean(asarray(image), axis=(0,1))\n",
    "print(data)\n",
    "song = create_song(load_files(), load_speeches(data[0], data[1], data[2]), data[0], data[1], data[2])\n",
    "play(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='./examples/5.mp3'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song.export(\"./examples/5.mp3\", format=\"mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
